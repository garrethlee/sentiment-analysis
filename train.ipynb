{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b538709-a378-4bfd-a3d8-c86eb3148537",
   "metadata": {},
   "source": [
    "# Sentiment Detection: An end to end project\n",
    "\n",
    "Sentiment analysis is a thoroughly researched and discussed topic, but the field is still making improvements and discovering new techniques everyday. While there are plenty of pre-trained models capable of achieving incredible precision in sentiment detection (especially models with complicated architectures, such as BERTs and RNNs), I set out to create my own implementation trained from data that is cleaned and processed from its raw, textual form. The goal of this project is to address and try to develop a model that possesses a few key aspects that a (binary) sentiment classifier should have, which I have outlined below:\n",
    "\n",
    "- Negation Handling (classifiying `not bad` as positive, `don't like` as negative)\n",
    "- Sarcasm (classifiying `This is exactly what I needed right now` as negative)\n",
    "- many more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e9bcaad-9a69-43d1-9223-f55762d5d40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /Users/garrethlee/opt/miniconda3/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /Users/garrethlee/opt/miniconda3/lib/python3.9/site-packages (from kaggle) (2022.9.24)\n",
      "Requirement already satisfied: python-dateutil in /Users/garrethlee/opt/miniconda3/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /Users/garrethlee/opt/miniconda3/lib/python3.9/site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/garrethlee/opt/miniconda3/lib/python3.9/site-packages (from kaggle) (4.64.1)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in /Users/garrethlee/opt/miniconda3/lib/python3.9/site-packages (from kaggle) (1.26.11)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m359.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /Users/garrethlee/opt/miniconda3/lib/python3.9/site-packages (from requests->kaggle) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/garrethlee/opt/miniconda3/lib/python3.9/site-packages (from requests->kaggle) (2.0.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73031 sha256=d1a5cdca068f84371f25b3ccb46f9a8a1b635769cc6adfd18f629a3f2409f78e\n",
      "  Stored in directory: /Users/garrethlee/Library/Caches/pip/wheels/ac/b2/c3/fa4706d469b5879105991d1c8be9a3c2ef329ba9fe2ce5085e\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-6.1.2 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf36cda-314e-460f-a272-c9c1a48533e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preliminary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d128b9-f21f-434a-a034-30cab7d7075f",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "The data used for this analysis is the [Sentiment140 Dataset](https://www.kaggle.com/datasets/kazanova/sentiment140), which contains 1.6 million tweets extracted from the twitter API. We'll conduct a few simple preprocessing steps to format the data into a model-friendly shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e69baf9-2b37-457b-993d-a1ca62fd565f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0\n",
       "1  is upset that he can't update his Facebook by ...          0\n",
       "2  @Kenichan I dived many times for the ball. Man...          0\n",
       "3    my whole body feels itchy and like its on fire           0\n",
       "4  @nationwideclass no, it's not behaving at all....          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(path = \"./tweets.csv\"):\n",
    "    \"\"\"Loads tweets csv onto a pandas DataFrame\"\"\"\n",
    "\n",
    "    columns = [\"sentiment\", \"tweet_id\", \"date\", \"query\", \"username\", \"tweet\"]\n",
    "\n",
    "    data = pd.read_csv('tweets.csv', \n",
    "                       encoding='latin', \n",
    "                       header = None, \n",
    "                       names = columns)\n",
    "\n",
    "    data = data[['tweet', 'sentiment']]\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbdf7d7-f493-4250-b034-b0660d818746",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974428bc-0532-4d58-9561-7bf6f51f3493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "4    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c9a2c-7351-457f-a952-b43ea5c86ace",
   "metadata": {},
   "source": [
    "To make the data more interpretable, we'll change 4 to 1 (positive sentiment) and keep 0 (negative sentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f11061-589f-4455-9bab-def204fb6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['sentiment'].replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9577ebaa-8787-41ea-a6d3-95ac2c450d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0\n",
       "1  is upset that he can't update his Facebook by ...          0\n",
       "2  @Kenichan I dived many times for the ball. Man...          0\n",
       "3    my whole body feels itchy and like its on fire           0\n",
       "4  @nationwideclass no, it's not behaving at all....          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2369e5-563b-4366-9107-04a657773f4d",
   "metadata": {},
   "source": [
    "For this project, we'll use 200.000 rows of data to speed up training times, with a 80-20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a928eb-bf9b-47ae-9a99-5653db21591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def split_data(data, rows_used, target = 'sentiment', test_size = 0.2):\n",
    "    \"\"\"Performs a stratiffied shuffle split (maintaining class balance between train and test splits)\"\"\"\n",
    "    \n",
    "    X = data.drop([target], axis = 1)\n",
    "    y = data[target]\n",
    "\n",
    "    sss = StratifiedShuffleSplit(test_size = test_size)\n",
    "\n",
    "    for train_indices, test_indices in sss.split(X, y):\n",
    "        train_X, train_y = X.iloc[train_indices], y.iloc[train_indices]\n",
    "        test_X, test_y = X.iloc[test_indices], y.iloc[test_indices]\n",
    "        \n",
    "    pre_train_X, pre_train_y = train_X.iloc[:rows_used], train_y.iloc[:rows_used]\n",
    "    test_X, test_y = test_X.iloc[:rows_used], test_y.iloc[:rows_used]\n",
    "    \n",
    "    for train_indices, val_indices in sss.split(pre_train_X, pre_train_y):\n",
    "        train_X, train_y = pre_train_X.iloc[train_indices], pre_train_y.iloc[train_indices]\n",
    "        val_X, val_y = pre_train_X.iloc[val_indices], pre_train_y.iloc[val_indices]\n",
    "    \n",
    "    return train_X, val_X, test_X, train_y, val_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f65c05-e3a1-48ef-ba6a-fb2dae629457",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, test_X, train_y, val_y, test_y = split_data(data, rows_used = 300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbabe62-b26e-42f3-b4b5-5fb8f6cd6fbc",
   "metadata": {},
   "source": [
    "## Basic Text Transformation\n",
    "\n",
    "Let's take a sample tweet to figure out what features exist in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79207b3c-4ad4-4c89-8db0-8421641ccdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@andyclemmensen heyyy you ALWAYS look nice  wanna come to my friend's party? its june 8th long weekend in sydney \n",
      "@penguinloverwoo me too! So sore. Moving furniture plus DDR equals bodily harm \n",
      "@drewbilation Thanx very much. I do try \n",
      "Cooky's got a new motor - anyone had their Audi stolen in the Ayrshire area?  \n",
      "Hero's was amazing tonight OMG! cant wait until next week \n"
     ]
    }
   ],
   "source": [
    "print(*data['tweet'].sample(5).values.squeeze(), sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8629f3dd-9ef5-493b-9d1c-ee2be6ad719f",
   "metadata": {},
   "source": [
    "From the sample, we can see some key non-speech features present in tweets:\n",
    "- Tagged usernames - accounts (denoted with '@' tagged within the tweet)\n",
    "- Hashtags\n",
    "- URLs\n",
    "- Digits that need to be converted to text\n",
    "- Others (Apostrophes, blank spaces, punctuation, etc.)\n",
    "\n",
    "We'll have to find solutions to remove/replace these words in the tweet. The `clean` function below uses regex to remove these non-speech features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e931e2a0-4d06-4135-9ce7-70ebf1c61bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360572</th>\n",
       "      <td>user probably either way f cked as still not g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613863</th>\n",
       "      <td>thinking that the feed posts a lot of shit but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295682</th>\n",
       "      <td>user make me one too lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220455</th>\n",
       "      <td>hmmm i wake up and find that my home file amp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691118</th>\n",
       "      <td>god i really really need to study i like kidne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet\n",
       "360572   user probably either way f cked as still not g...\n",
       "613863   thinking that the feed posts a lot of shit but...\n",
       "1295682                          user make me one too lol \n",
       "220455   hmmm i wake up and find that my home file amp ...\n",
       "691118   god i really really need to study i like kidne..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean(t):\n",
    "    \"\"\"Replaces non-speech features in tweets with regex\"\"\"\n",
    "    \n",
    "    URL_PATTERN = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\"\n",
    "    HASHTAG_PATTERN = r\"#\\S+[a-zA-Z]\"\n",
    "    USERNAME_PATTERN = r\"@[a-zA-Z]\\S*\"\n",
    "    NUMBER_PATTERN = r\"\\d+\"\n",
    "    APOSTROPHE_PATTERN = r\"\\w+'\\w+\"\n",
    "    NONWORD_PATTERN = r\"[^a-zA-Z]+\"\n",
    "\n",
    "    t = re.sub(HASHTAG_PATTERN, \"HASHTAG\", t)\n",
    "    t = re.sub(URL_PATTERN, \"URL\", t)\n",
    "    t = re.sub(USERNAME_PATTERN, \"USER\", t)\n",
    "    t = re.sub(APOSTROPHE_PATTERN, \"\", t)\n",
    "    t = re.sub(NUMBER_PATTERN, \"NUMBER\", t)\n",
    "    t = re.sub(NONWORD_PATTERN, \" \", t)\n",
    "    \n",
    "    return t.lower()\n",
    "\n",
    "# See the clean() function in action\n",
    "train_X['tweet'] = train_X['tweet'].apply(clean)\n",
    "val_X['tweet'] = val_X['tweet'].apply(clean)\n",
    "test_X['tweet'] = test_X['tweet'].apply(clean)\n",
    "\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd9da43-6385-48b8-a7de-a11e5f019dee",
   "metadata": {},
   "source": [
    "After stripping non-speech words, we might end up with rows that just have an empty string. We'll remove these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b17d64ee-d1b9-4085-abfe-f681bd398d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 1 rows from train_X\n",
      "Removing 0 rows from val_X\n",
      "Removing 5 rows from test_X\n"
     ]
    }
   ],
   "source": [
    "print(f\"Removing {sum(train_X['tweet'].str.strip() == '')} rows from train_X\")\n",
    "train_y = train_y[train_X['tweet'].str.strip() != \"\"]\n",
    "train_X = train_X[train_X['tweet'].str.strip() != \"\"]\n",
    "\n",
    "print(f\"Removing {sum(val_X['tweet'].str.strip() == '')} rows from val_X\")\n",
    "val_y = val_y[val_X['tweet'].str.strip() != \"\"]\n",
    "val_X = val_X[val_X['tweet'].str.strip() != \"\"]\n",
    "\n",
    "\n",
    "print(f\"Removing {sum(test_X['tweet'].str.strip() == '')} rows from test_X\")\n",
    "test_y = test_y[test_X['tweet'].str.strip() != \"\"]\n",
    "test_X = test_X[test_X['tweet'].str.strip() != \"\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3632d71-a448-4421-869b-cd51678084d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Advanced Text Transformation\n",
    "\n",
    "Now, we apply *slightly more* complicated transformations to the text. The goal? To further condense the text without reducing its information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf69b8bf-4116-4518-a890-efa339a080bc",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "When we lemmatize, we abstract the word to its simplest form. Plural nouns get stripped down to its singular form, continous verbs to its base verb form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7ca2ef-6e68-40bf-bbcc-426e4ad91523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def lemmatize_data(texts):\n",
    "\n",
    "    lemmatized = []\n",
    "\n",
    "    for doc in nlp.pipe(texts.values, batch_size=100, n_process=-1, disable=[\"parser\", \"ner\"]):\n",
    "        lemmatized.append(\" \".join([tok.lemma_ for tok in doc]))\n",
    "        \n",
    "    print(\"Done lemmatizing texts!\")\n",
    "    \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "196a46f7-8d2f-40ed-a689-4d9d79b89315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done lemmatizing texts!\n",
      "Done lemmatizing texts!\n",
      "Done lemmatizing texts!\n"
     ]
    }
   ],
   "source": [
    "lemmatized_train_X = pd.Series(lemmatize_data(train_X['tweet']))\n",
    "lemmatized_val_X = pd.Series(lemmatize_data(val_X['tweet']))\n",
    "lemmatized_test_X = pd.Series(lemmatize_data(test_X['tweet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa8f4d-bb3e-48fb-9b41-a65bbd426461",
   "metadata": {},
   "source": [
    "### Removing Stopwords\n",
    "\n",
    "We can cut down the meaningless words that appear often (stopwords) to help the model focus on the words that matter and abstract them away from the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "724fa434-05a3-41bb-84f7-06d2233b69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(sent):\n",
    "    \n",
    "    \"\"\"Removes stopwords from a given sentence\"\"\"\n",
    "    stop_words = stopwords.words('english')\n",
    "    # Maintain negation in final data\n",
    "    stop_words.remove('not')\n",
    "    # remove apostrophes from stopwords\n",
    "    final_stop_words = list(map(lambda x: re.sub(r'\\W+', '', x), stop_words))\n",
    "        \n",
    "    return (\" \".join([word for word in sent.split() if word not in final_stop_words])).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bf6b9e2-76bb-4335-95dc-b83248d82649",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_X = lemmatized_train_X.apply(remove_stopwords)\n",
    "cleaned_val_X = lemmatized_val_X.apply(remove_stopwords)\n",
    "cleaned_test_X = lemmatized_test_X.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f770fe-9f20-4711-9763-9ef963395eee",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6032080-2999-4464-8c9a-66a0860743b2",
   "metadata": {},
   "source": [
    "We're going to try several different approaches and see which features provide the best performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b535ac8-7274-4856-8900-18f84094bcc6",
   "metadata": {},
   "source": [
    "## TF-IDF Vectors\n",
    "\n",
    "TF stands for term frequency, while IDF stands for inverse document frequency. These terms are pretty much self explanatory\n",
    "\n",
    "$$\\large{w_{x,y}=tf_{x,y}*log(\\frac{N}{count{x,y}})}$$\n",
    "\n",
    "The **tf-idf** score for a given word (x) in a sentence (y) is the number of times the word appears in the sentence multiplied by the logarithm of the number of sentences divided by the number of sentences the word appears in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c337e7f8-8522-49db-8c5e-0611a17a3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# only include unigrams\n",
    "tf_1 = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "new_train_X = tf_1.fit_transform(lemmatized_train_X)\n",
    "new_val_X = tf_1.transform(lemmatized_val_X)\n",
    "new_test_X = tf_1.transform(lemmatized_test_X)\n",
    "\n",
    "tf_2 = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "new_train_X_bi = tf_2.fit_transform(cleaned_train_X)\n",
    "new_val_X_bi = tf_2.transform(cleaned_val_X)\n",
    "new_test_X_bi = tf_2.transform(cleaned_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba05a894-cddc-4b3a-841e-a71315d084c1",
   "metadata": {},
   "source": [
    "Here, the `ngram_range` sets the ngram tokens that we want to include in the vectorizer. This means that instead of only looking at the term frequency of **unigrams** (single words), the model now learns the TF-IDF values of **bigrams** (two words). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ad546-90b2-4a18-9c92-a64a19913788",
   "metadata": {},
   "source": [
    "## Count Vectors\n",
    "\n",
    "Count vectorization simply takes every word in the corpus, assigns it an index, and assigns a count value corresponding to each index in every sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53585602-6a43-4f01-b03e-ca3b9ce017a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "vectorized_train_X = cv.fit_transform(cleaned_train_X)\n",
    "vectorized_val_X = cv.transform(cleaned_val_X)\n",
    "vectorized_test_X = cv.transform(cleaned_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c660372a-400d-4c4a-ba33-5578f7b2dbbf",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638190f-fc2f-4b85-9365-3e32c720f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the lemmatized, but not cleaned values. This is to make sure that the model can learn associations between the position of the word within the sentence \n",
    "\n",
    "train_texts = lemmatized_train_X.values\n",
    "val_texts = lemmatized_val_X.values\n",
    "test_texts = lemmatized_test_X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2ee94c1-3598-4332-bec9-047ecc3c79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = 3000)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(train_texts)\n",
    "val_seq = tokenizer.texts_to_sequences(val_texts)\n",
    "\n",
    "# Pad all sequences to have the same length for training\n",
    "train_X_padded = pad_sequences(train_seq, maxlen=200)\n",
    "val_X_padded = pad_sequences(val_seq, maxlen=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6a75d-6950-437b-8ec3-e8fc1bc2ae49",
   "metadata": {},
   "source": [
    "Our goal is to get a numerical representation of each word in the corpus. We will use one of GENSIM Word2Vec's models to get our embedding matrix. Then, we will use this matrix as input to create a tensorflow `Embedding` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0ca5e9b-47f8-492f-a2d8-db1b95a6f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "def get_embedding_weights(sentences, vector_size = 200, vocab_size = 5000, return_vocab_size = True):\n",
    "    \"\"\"Returns Word2Vec embeddings from given corpus\"\"\"\n",
    "        \n",
    "    w2v = Word2Vec(sentences = [sent.split() for sent in train_texts], vector_size = vector_size, max_vocab_size=vocab_size)\n",
    "    w2v.build_vocab([sent.split() for sent in train_texts] ,keep_raw_vocab=True)\n",
    "    \n",
    "    embedding_weights = np.zeros((vocab_size, vector_size))\n",
    "    \n",
    "    for word, index in w2v.wv.key_to_index.items():\n",
    "        embedding_weights[index] = w2v.wv[word]\n",
    "        \n",
    "    if return_vocab_size:\n",
    "        size = len(w2v.raw_vocab)\n",
    "        return embedding_weights, size\n",
    "    \n",
    "    return embedding_weights\n",
    "    \n",
    "embedding_weights, vocab_size = get_embedding_weights(train_texts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757878c7-dac8-402b-b4e7-c56355b93699",
   "metadata": {},
   "source": [
    "Next, we'll create the model architecture alongside the `Embedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08ba5666-90b5-488e-ae4e-1fadb7e5adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(input_dim = 5000,\n",
    "                            output_dim = 200,\n",
    "                            weights = [embedding_weights],\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09d6b803-bac2-4529-b809-15c2ec1c6c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Dropout, Bidirectional, LSTM\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"Create model architecture and compile with metrics\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Bidirectional(LSTM(units=64)))\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer = Adam(learning_rate = 0.001), \n",
    "                  loss = 'binary_crossentropy', \n",
    "                  metrics = 'accuracy',)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6498f580-0163-4ef4-ae96-f53cfc5ab690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_X_padded[:20000], train_y[:20000], epochs = 20, verbose = 2, validation_data=(val_X_padded[:500], val_y[:500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3adbf2a-9300-432f-b224-f6556ba05989",
   "metadata": {},
   "source": [
    "# Baseline Modelling + Feature Selection\n",
    "\n",
    "We'll test a few common classifiers to find the best baseline model. We'll build upon this base model for future iterations.\n",
    "\n",
    "Also, we'll use each model to test out the performances of using different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1adb237f-ec6a-470d-a10f-3bbb0502e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, roc_auc_score\n",
    "\n",
    "\n",
    "def eval_metrics(pred, actual):\n",
    "    \"\"\"Calculate various metrics from the model's predictions\"\"\"\n",
    "    precision = precision_score(actual, pred)\n",
    "    f1 = f1_score(actual, pred)\n",
    "    recall = recall_score(actual, pred)\n",
    "    roc_auc = roc_auc_score(actual, pred)\n",
    "    return precision, f1, recall, roc_auc\n",
    "    \n",
    "\n",
    "models = dict(\n",
    "    # logistic_regression = LogisticRegression(max_iter=500),\n",
    "    svc = SVC()\n",
    "    # dummy_classifier = DummyClassifier(strategy='uniform'),\n",
    "    # adaboost_classifier = AdaBoostClassifier(),\n",
    "    # xgboost = XGBClassifier(),\n",
    "    # decision_tree = DecisionTreeClassifier(),\n",
    "    # MLP = MLPClassifier(),\n",
    "    # rf = RandomForestClassifier(n_estimators = 150)\n",
    ")\n",
    "\n",
    "features = {'Unigram TF-IDF':(new_train_X, new_val_X, new_test_X),\n",
    "            'Bigram TF-IDF': (new_train_X_bi, new_val_X_bi, new_test_X_bi),\n",
    "            'Count Vectorizer':(vectorized_train_X, vectorized_val_X, vectorized_test_X)}\n",
    "\n",
    "baseline_results = []\n",
    "\n",
    "for model in models:\n",
    "    metrics = {\"model\": model}\n",
    "    for feature_name, (train, val, test) in features.items():\n",
    "        m = models[model]\n",
    "        m.fit(train[:100000], train_y[:100000])\n",
    "        preds = m.predict(val)\n",
    "        precision, f1, recall, roc_auc = eval_metrics(preds, val_y)\n",
    "        # Merge dicts together\n",
    "        metrics = {**metrics, **{(feature_name, \"precision\"):precision, (feature_name, \"f1 score\"):f1,(feature_name, \"recall\"):recall, (feature_name, \"roc auc score\"):roc_auc}}\n",
    "    baseline_results.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab93bf4-b32e-4a71-8c4b-2c5f6534a0cf",
   "metadata": {},
   "source": [
    "We'll display the results in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f24bb413-328a-4628-990e-b32b23a2c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_col_index(results):\n",
    "    \"\"\"Return row indices (model names) and column indices (MultiIndex) for the results dataframe\"\"\"\n",
    "    \n",
    "    rows, cols = [], []\n",
    "    \n",
    "    for mod in results:\n",
    "        rows.append(list(mod.values())[0])\n",
    "        cols.append(list(mod.keys())[1:])\n",
    "        \n",
    "    col_index = pd.MultiIndex.from_tuples(cols[0])\n",
    "    row_index = rows\n",
    "    \n",
    "    return row_index, col_index\n",
    "\n",
    "row_index, col_index = get_row_col_index(baseline_results)\n",
    "baseline_df = pd.DataFrame(baseline_results, index=row_index, columns = col_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d37ee-62a7-44e9-8f57-f48b7c15600f",
   "metadata": {},
   "source": [
    "Since we've balanced out the datasets, we'll use the ROC-AUC score as an indicator of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f7a7904-4b3a-43d3-9da2-50d4c29ffd59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Unigram TF-IDF</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Bigram TF-IDF</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Count Vectorizer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc auc score</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc auc score</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc auc score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>0.683</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.697</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiLayer Perceptron</th>\n",
       "      <td>0.766</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Unigram TF-IDF                                \\\n",
       "                           precision f1 score recall roc auc score   \n",
       "Logistic Regression            0.775    0.786  0.796         0.782   \n",
       "Dummy                          0.502    0.501  0.500         0.501   \n",
       "Adaboost                       0.683    0.728  0.780         0.708   \n",
       "XGBoost                        0.741    0.765  0.790         0.757   \n",
       "Decision Tree                  0.697    0.701  0.705         0.699   \n",
       "MultiLayer Perceptron          0.766    0.759  0.752         0.761   \n",
       "Random Forest                  0.783    0.778  0.773         0.779   \n",
       "svc                            0.781    0.793  0.805         0.789   \n",
       "\n",
       "                      Bigram TF-IDF                                \\\n",
       "                          precision f1 score recall roc auc score   \n",
       "Logistic Regression           0.773    0.781  0.789         0.778   \n",
       "Dummy                         0.501    0.501  0.502         0.500   \n",
       "Adaboost                      0.712    0.680  0.651         0.693   \n",
       "XGBoost                       0.739    0.734  0.729         0.735   \n",
       "Decision Tree                 0.703    0.706  0.710         0.704   \n",
       "MultiLayer Perceptron         0.768    0.771  0.774         0.770   \n",
       "Random Forest                 0.765    0.770  0.774         0.768   \n",
       "svc                           0.765    0.781  0.797         0.776   \n",
       "\n",
       "                      Count Vectorizer                                \n",
       "                             precision f1 score recall roc auc score  \n",
       "Logistic Regression              0.756    0.770  0.785         0.766  \n",
       "Dummy                            0.501    0.501  0.501         0.500  \n",
       "Adaboost                         0.710    0.681  0.654         0.694  \n",
       "XGBoost                          0.736    0.739  0.742         0.738  \n",
       "Decision Tree                    0.703    0.698  0.692         0.700  \n",
       "MultiLayer Perceptron            0.669    0.716  0.770         0.694  \n",
       "Random Forest                    0.767    0.758  0.749         0.761  \n",
       "svc                              0.757    0.779  0.803         0.772  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df.apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d6b3a-f301-4731-b089-4a2335c3b302",
   "metadata": {},
   "source": [
    "From the table above, we see that the **SVC** classifier got the highest ROC-AUC score, with the **Unigram TF-IDF** word embeddings being the best performing feature set! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0505033e-93dc-4dc5-bd08-ee36ec9000bc",
   "metadata": {},
   "source": [
    "# Pipeline Creation\n",
    "\n",
    "Now, we're going to create a modelling pipeline that:\n",
    "\n",
    "- takes in raw text, \n",
    "- preprocesses it (strip away stopwords, perform tokenization, and lemmatize the data)\n",
    "- applies the best performing feature encoding (which in our case was the bigram Tf-Idf vectorizer), then \n",
    "- inputs the transformed data into a logistic regression model to produce a prediction on sentiment\n",
    "\n",
    "Since we want to preprocess text, we can create a custom transformer using sklearn's TransformerMixin class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd11742-4c40-4d44-92b7-8f7f43085301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SentimentDetectorPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes a sklearn transformer that'll preprocess textual data\"\"\"\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "         \n",
    "\n",
    "    def clean(self, t):\n",
    "        \n",
    "        \"\"\"Replaces non-speech features in tweets with regex\"\"\"\n",
    "\n",
    "        URL_PATTERN = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\"\n",
    "        HASHTAG_PATTERN = r\"#\\S+[a-zA-Z]\"\n",
    "        USERNAME_PATTERN = r\"@[a-zA-Z]\\S*\"\n",
    "        NUMBER_PATTERN = r\"\\d+\"\n",
    "        APOSTROPHE_PATTERN = r\"\\w+'\\w+\"\n",
    "        NONWORD_PATTERN = r\"[^a-zA-Z]+\"\n",
    "\n",
    "        t = re.sub(HASHTAG_PATTERN, \"HASHTAG\", t)\n",
    "        t = re.sub(URL_PATTERN, \"URL\", t)\n",
    "        t = re.sub(USERNAME_PATTERN, \"USER\", t)\n",
    "        t = re.sub(APOSTROPHE_PATTERN, \"\", t)\n",
    "        t = re.sub(NUMBER_PATTERN, \"NUMBER\", t)\n",
    "        t = re.sub(NONWORD_PATTERN, \" \", t)\n",
    "\n",
    "        return t.lower()\n",
    "        \n",
    "    def remove_stopwords(self, tokens):\n",
    "        \"\"\"Removes stopwords from a given sentence\"\"\"        \n",
    "\n",
    "        stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "        \n",
    "        # remove apostrophes from stopwords\n",
    "        final_stop_words = list(map(lambda x: re.sub(r'\\W+', '', x), stopwords))\n",
    "\n",
    "        return (\" \".join([word for word in tokens if word not in final_stop_words])).lower()\n",
    "\n",
    "\n",
    "    def lemmatize_data(self, text):\n",
    "        return [self.lemmatizer.lemmatize(tok) for tok in text.split()]\n",
    "\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y = None):\n",
    "        if type(X) == pd.DataFrame:\n",
    "            X = X['tweet'] \n",
    "        if type(X) != pd.Series:\n",
    "            X = pd.Series(X)\n",
    "        \n",
    "        data = X.apply(self.clean)\n",
    "        data = data.apply(self.lemmatize_data)\n",
    "        data = data.apply(self.remove_stopwords)\n",
    "        return data\n",
    "    \n",
    "    def fit_transform(self, X, y = None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23f8fa8e-c722-401d-8ea6-4ab7a3941add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils.transformer import SentimentDetectorPreprocessor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# best_model = gs.best_estimator_\n",
    "\n",
    "pipe = Pipeline(steps = [('sd_processor', SentimentDetectorPreprocessor()),\n",
    "                         ('tf-idf_vectorizer', TfidfVectorizer(ngram_range = (1,3), max_features = 50000)),\n",
    "                         ('SVC', SVC(probability = True, gamma = 'auto'))])\n",
    "\n",
    "# Train\n",
    "pipe.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99d7ba5a-67ea-4a8b-918d-1651b85841c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78    145334\n",
      "           1       0.80      0.77      0.79    154661\n",
      "\n",
      "    accuracy                           0.78    299995\n",
      "   macro avg       0.78      0.78      0.78    299995\n",
      "weighted avg       0.78      0.78      0.78    299995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display metrics from test dataset\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(pipe.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f32bee-b074-4ca1-99a3-5092a4712b4e",
   "metadata": {},
   "source": [
    "We'll pickle the model to get a `pkl` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb8401de-f75e-49c3-8518-b2c87251f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e230cf-071f-4780-a9eb-f7d3834d1247",
   "metadata": {},
   "source": [
    "# Final Thoughts\n",
    "\n",
    "- We ultimately ended up with a **Suport Vector Classifier**, using TF-IDF vectors as a feature for the model. In the balanced testing dataset, the model got an accuracy of .\n",
    "\n",
    "- After testing the initial model with respect to the goals in the introduction,he model was able to pick up some simple negations (`not good`, `dont like`, `not the best`), but still struggled with others (`not bad`, `dont hate`). This can be attributed to several factors, some of them being possible spelling errors, as well as well as not enough training data.\n",
    "\n",
    "- For future iterations, we could possibly incorporate hyperparameter tuning into the fold, such as using `GridSearch` to pick the best kernel for the SVC. Also, if we had more access to memory, we could possibly train the model on the entire dataset, so the model can pick up more common phrases that can help in sentiment detection.\n",
    "\n",
    "*Thanks for sticking around this far, until next time! 👋*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "011169fad7be4076920a80f8892b37fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a634adde97364f2182fec1873eecccf4",
       "style": "IPY_MODEL_5a03878a46e84ba2a684a01dbd2228c2",
       "value": " 22.7M/22.7M [00:01&lt;00:00, 12.6MB/s]"
      }
     },
     "014e9bf964be4264b82af7a30a7caa00": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0164fd9f88c1469b97eee5364d29a0e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d633472eb37b4d1db38c55815645d22e",
        "IPY_MODEL_ae9f1a26591147df9c276748d777a54a",
        "IPY_MODEL_db6d8ac062b54db0aefbd49a76448767"
       ],
       "layout": "IPY_MODEL_c73c2220e8114c98ae1b83a8f1e8341f"
      }
     },
     "048a12f4604c4741a686fae061acdbdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0e5cc07f6c824922ae033830eee45fd1",
        "IPY_MODEL_49bd76b592424b9fa50c013c568de344",
        "IPY_MODEL_f037844d7e9a4b069cb0d6dada731b4c"
       ],
       "layout": "IPY_MODEL_80522cd3787b4ed292481c4217d6dfaa"
      }
     },
     "0502d4031a4446328ded81e647ceec98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "052d6f0e1df94675a3e728e9de0373a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4cd2bf0297e54eaf92e95595c968cedd",
       "style": "IPY_MODEL_93d40de5b0db4249a5285fdd2dba73bb",
       "value": " 647k/647k [00:00&lt;00:00, 3.64MB/s]"
      }
     },
     "0602c4a023714a40aa9dbe117a6ef248": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6641adee27374e2e8949cde37bbc0b36",
        "IPY_MODEL_ef4a3377b12d483e86c419692a871830",
        "IPY_MODEL_011169fad7be4076920a80f8892b37fa"
       ],
       "layout": "IPY_MODEL_9772e9f19bbd4e128fc0af353b2e7836"
      }
     },
     "0e5cc07f6c824922ae033830eee45fd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_77d2b90e8ecb4a72ac28d847465a077a",
       "style": "IPY_MODEL_11e3fcf092424fc48b79a930350aa7ca",
       "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: "
      }
     },
     "0f6966a118434f71a6b9a610fe5b7f64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "11e3fcf092424fc48b79a930350aa7ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "120893e07af54a4cb2c8233507870448": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "16fc7f150dd94928b5cfc7fa0f53235a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1955893d7805412d86f7fbae454eebfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_898b0465a1be434a9ac6e2108cb3a064",
       "style": "IPY_MODEL_abe156eb2c064917a82d1c52ee38cf9f",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/ner/ontonotes.pt: 100%"
      }
     },
     "1a103333728f4904a80e5d1880fc1b03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9781a82710e44bb2b1bc135a97087dfd",
       "style": "IPY_MODEL_e833b1fca43f4a9f8ce2e0d6ab472619",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/tokenize/combined.pt: 100%"
      }
     },
     "1a71a7de79b145cbb2e39cdbe5681391": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1e55e85ece5e4a39ba1bd33ee15c1568": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "20aadd48ea6949c9a2dfce3297638787": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_840527504c864ddb9441488818f2b333",
        "IPY_MODEL_8da3d58b25f94144a7f719bd4770845d",
        "IPY_MODEL_87b544996d5e40df9fdfe8658bb660ea"
       ],
       "layout": "IPY_MODEL_f5b4faa5ff20486aac8140f48bf9ca0e"
      }
     },
     "20ffbcc7bb8f4702a7c2b10d685470f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_63b390abdc2d4e29be3bddf10cc1e9c8",
       "style": "IPY_MODEL_d57050b6250f4f5289b8f612e881bbae",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/sentiment/sstplus.pt: 100%"
      }
     },
     "2207872f8666452488009189c1f75497": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "24e351c723244a23aa43c05a125cf389": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "26e970211b014aa1a57e91c2ff4e24ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "27bd5db9fa0c4773885d7a9e0e7c6ec2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2b34e7d0e0c14549a982e771b24593e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2fee4e3469c5487ca5989d9d7294926d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "32a1312ddb2343aa98143b4d5ace4877": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3417067fee4b4b90a848804e4d2259db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "350a22e762fe4afb9e75b5ecdf3729fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "35b8801b2bd74b3d8192dcea2f4a3763": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "36b957d1cfa54947ad4d2dd4ba10bb39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b9664c6ab73b4a9c9cf3144d92cd5cdc",
       "max": 4169580,
       "style": "IPY_MODEL_94f3480a6e744b73ac1acd6f884318be",
       "value": 4169580
      }
     },
     "377023a279ad42c39ff215395a04a936": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_35b8801b2bd74b3d8192dcea2f4a3763",
       "style": "IPY_MODEL_b4e9804435ec42bb94a2ca7f1f0f8f38",
       "value": " 113M/113M [00:12&lt;00:00, 8.78MB/s]"
      }
     },
     "3aed5bb2822f48e2916adacf3f0f2bb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7d608b4ecb5b4ad4b0785980a0248962",
        "IPY_MODEL_504948dc1900490d9c23dd96a1a579af",
        "IPY_MODEL_5ce4ae6fa80341b096d80e0a103f9d87"
       ],
       "layout": "IPY_MODEL_a0d451c92d374ce0821ec2761569ae39"
      }
     },
     "3d3bd9051afe468cbf083d952310e567": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3d998f110ae0405199bcf000d874f7a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3fc2771dddd4499b85eee2f86e26b458": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "404b2f5317d04eacaf5e921240efb00f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4a8ddbb073204a34b24c1e6491d0b574",
        "IPY_MODEL_8b8c9fae85f14aeabe166187cfc460d8",
        "IPY_MODEL_597a3716046d4da79b2d9bf35fb9a805"
       ],
       "layout": "IPY_MODEL_3fc2771dddd4499b85eee2f86e26b458"
      }
     },
     "40603b531f204f0db18b3ee4c1bfbb97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4e83f11741c9416aa5de945a70c6684d",
       "style": "IPY_MODEL_992d619b4ea54de4a34e0a753d035251",
       "value": " 4.17M/4.17M [00:00&lt;00:00, 4.10MB/s]"
      }
     },
     "42898de570e745cd945a879896564f40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4575848f050442a0839aac65c6f43869": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c59fe93e85f64e33a63bd3759bb4c0f9",
       "style": "IPY_MODEL_1e55e85ece5e4a39ba1bd33ee15c1568",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/pos/combined.pt: 100%"
      }
     },
     "49bd76b592424b9fa50c013c568de344": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_aaff69fbf535400bb79e5185a3bbfe82",
       "max": 28785,
       "style": "IPY_MODEL_55ed7b04bd624504b74062e1c6dc0212",
       "value": 28785
      }
     },
     "4a8ddbb073204a34b24c1e6491d0b574": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fcc5218ac4e144ef843e3e15a3aee961",
       "style": "IPY_MODEL_76ab66ae5283451e83a3da5508f90a2d",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/pretrain/fasttextcrawl.pt: 100%"
      }
     },
     "4b92f64544af4be7992654b067fda995": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4cd2bf0297e54eaf92e95595c968cedd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4e83f11741c9416aa5de945a70c6684d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "504948dc1900490d9c23dd96a1a579af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_63f2e9031b7c4d3393d25bbef7a058d8",
       "max": 109285372,
       "style": "IPY_MODEL_1a71a7de79b145cbb2e39cdbe5681391",
       "value": 109285372
      }
     },
     "508fe40951dd4013ba5e247fa92f809f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7b9d102104e1431aa6be82148f2b6011",
       "style": "IPY_MODEL_2b34e7d0e0c14549a982e771b24593e8",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/constituency/wsj.pt: 100%"
      }
     },
     "55ed7b04bd624504b74062e1c6dc0212": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "56e8e8ce3deb4a9389b6f924b4b5d7da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1955893d7805412d86f7fbae454eebfd",
        "IPY_MODEL_def6ee3b20964d1c828ed9ec9167c024",
        "IPY_MODEL_f0b6d02d55014703a83b12b59b6eb3b9"
       ],
       "layout": "IPY_MODEL_876842052eeb4387914bf5a3b65dd28a"
      }
     },
     "597a3716046d4da79b2d9bf35fb9a805": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a76412ebf507460b9475b8659761341b",
       "style": "IPY_MODEL_fb3203f0a6014eac9724d37693868fc9",
       "value": " 123M/123M [00:21&lt;00:00, 4.15MB/s]"
      }
     },
     "5a03878a46e84ba2a684a01dbd2228c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5b1aded517484dd39de23cd507f4d75c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1a103333728f4904a80e5d1880fc1b03",
        "IPY_MODEL_d2703eb420184eb2877c478e44977d16",
        "IPY_MODEL_052d6f0e1df94675a3e728e9de0373a6"
       ],
       "layout": "IPY_MODEL_d51a86d2cbc84d01b7168de769d025ac"
      }
     },
     "5b3758b8e2e94714accbb267436ebe4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_de12b9d4bf8444d0a4635736e878546e",
        "IPY_MODEL_c1896eb72f664e56b8aeb196f02c058b",
        "IPY_MODEL_c004f6a02bea46988fe6ee39598f9452"
       ],
       "layout": "IPY_MODEL_6783a0b7e4114b47a3bf11e676043142"
      }
     },
     "5ce4ae6fa80341b096d80e0a103f9d87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_86ef3f10814c45a582711909a9f17dfb",
       "style": "IPY_MODEL_871c66606b9648a6b1cefe461555302d",
       "value": " 109M/109M [00:13&lt;00:00, 7.11MB/s]"
      }
     },
     "5d58deab9c6f4aa8aaffe758b661a93b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_26e970211b014aa1a57e91c2ff4e24ff",
       "style": "IPY_MODEL_82f165b873484be3b633b4bf41102c9f",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/lemma/combined.pt: 100%"
      }
     },
     "63b390abdc2d4e29be3bddf10cc1e9c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "63f2e9031b7c4d3393d25bbef7a058d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "65e3ec9a2a9548fe9dc7b928ce8113e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6641adee27374e2e8949cde37bbc0b36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3d998f110ae0405199bcf000d874f7a6",
       "style": "IPY_MODEL_65e3ec9a2a9548fe9dc7b928ce8113e7",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/forward_charlm/1billion.pt: 100%"
      }
     },
     "6783a0b7e4114b47a3bf11e676043142": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "68f50b747cd34a3f93183d975edd7d84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4575848f050442a0839aac65c6f43869",
        "IPY_MODEL_e3a1961ffb0341b9a7e44bbe876f30d2",
        "IPY_MODEL_bae991246c9c44148e060d61f69a648c"
       ],
       "layout": "IPY_MODEL_f5ea18930223410a875714e11252c446"
      }
     },
     "71aaa40590224f0f9746a05e6c502c86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "76ab66ae5283451e83a3da5508f90a2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "77d2b90e8ecb4a72ac28d847465a077a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "79c670da94334c69b0d7f542f8d554b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7b56eb37d190499684143fb2064627db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7b9d102104e1431aa6be82148f2b6011": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7be3bd7d50394f52b9fc71b374c385f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7d608b4ecb5b4ad4b0785980a0248962": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_27bd5db9fa0c4773885d7a9e0e7c6ec2",
       "style": "IPY_MODEL_a4a10cc75518416bbb078bb14680bf97",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/depparse/combined.pt: 100%"
      }
     },
     "80522cd3787b4ed292481c4217d6dfaa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "82f165b873484be3b633b4bf41102c9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "840527504c864ddb9441488818f2b333": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_897057b0bbcd42ceb15c9069e4a70fd4",
       "style": "IPY_MODEL_42898de570e745cd945a879896564f40",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/backward_charlm/1billion.pt: 100%"
      }
     },
     "85b4d6b5e5d44c958905cc1ec15ebfe4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "86ef3f10814c45a582711909a9f17dfb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "871c66606b9648a6b1cefe461555302d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "876842052eeb4387914bf5a3b65dd28a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "87b544996d5e40df9fdfe8658bb660ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d29f3bc3867049f58b9f0958a8e6fbdf",
       "style": "IPY_MODEL_3d3bd9051afe468cbf083d952310e567",
       "value": " 22.7M/22.7M [00:04&lt;00:00, 6.70MB/s]"
      }
     },
     "897057b0bbcd42ceb15c9069e4a70fd4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "898b0465a1be434a9ac6e2108cb3a064": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8b8c9fae85f14aeabe166187cfc460d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_90099a18a98f49888f315c29e6a11371",
       "max": 122564243,
       "style": "IPY_MODEL_71aaa40590224f0f9746a05e6c502c86",
       "value": 122564243
      }
     },
     "8d5fe74725ee4d1a93b36aebf38d4547": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8da3d58b25f94144a7f719bd4770845d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_fa0f1760d0ee422cbafa113b26cec9f6",
       "max": 22743430,
       "style": "IPY_MODEL_79c670da94334c69b0d7f542f8d554b5",
       "value": 22743430
      }
     },
     "90099a18a98f49888f315c29e6a11371": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "93d40de5b0db4249a5285fdd2dba73bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "94f3480a6e744b73ac1acd6f884318be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9563425ba230490da4f2675953132e76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "970ae87c5c9f4e6b83d171f20be599c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9772e9f19bbd4e128fc0af353b2e7836": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9781a82710e44bb2b1bc135a97087dfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "992d619b4ea54de4a34e0a753d035251": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "99d87c48b21e4480890ac29b6eccb8de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9d3355b215664a93b583e019a62a0b1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_350a22e762fe4afb9e75b5ecdf3729fa",
       "max": 80439920,
       "style": "IPY_MODEL_ca12bd31c03a4b78b3b09a971a2c13f5",
       "value": 80439920
      }
     },
     "9eff93d2422b49ebabed7cda8ebfaad3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5d58deab9c6f4aa8aaffe758b661a93b",
        "IPY_MODEL_36b957d1cfa54947ad4d2dd4ba10bb39",
        "IPY_MODEL_40603b531f204f0db18b3ee4c1bfbb97"
       ],
       "layout": "IPY_MODEL_120893e07af54a4cb2c8233507870448"
      }
     },
     "a080be236a584c578650d9a57780a76d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a0d451c92d374ce0821ec2761569ae39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a4a10cc75518416bbb078bb14680bf97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a634adde97364f2182fec1873eecccf4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a76412ebf507460b9475b8659761341b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aaff69fbf535400bb79e5185a3bbfe82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "abe156eb2c064917a82d1c52ee38cf9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ac22c3e385844e4b98f9696f85cbc6df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ae0a226d4ba74488beb03b4e68e86d02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ae9f1a26591147df9c276748d777a54a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_32a1312ddb2343aa98143b4d5ace4877",
       "max": 28785,
       "style": "IPY_MODEL_3417067fee4b4b90a848804e4d2259db",
       "value": 28785
      }
     },
     "aec6fd99fdc448c48cfa0b34bc127907": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b419b65fd85942c68d072ef7763b8a91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b4e9804435ec42bb94a2ca7f1f0f8f38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b6ea31544baf4e588fc1d00dde1f686d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b9664c6ab73b4a9c9cf3144d92cd5cdc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bae991246c9c44148e060d61f69a648c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_014e9bf964be4264b82af7a30a7caa00",
       "style": "IPY_MODEL_9563425ba230490da4f2675953132e76",
       "value": " 38.5M/38.5M [00:05&lt;00:00, 8.58MB/s]"
      }
     },
     "c004f6a02bea46988fe6ee39598f9452": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b419b65fd85942c68d072ef7763b8a91",
       "style": "IPY_MODEL_aec6fd99fdc448c48cfa0b34bc127907",
       "value": " 107M/107M [00:14&lt;00:00, 10.5MB/s]"
      }
     },
     "c1896eb72f664e56b8aeb196f02c058b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_ff11d93057634345adc26b3dfe8f198b",
       "max": 106701198,
       "style": "IPY_MODEL_7b56eb37d190499684143fb2064627db",
       "value": 106701198
      }
     },
     "c440f1464fa7408caafcfd2dea6b4984": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c59fe93e85f64e33a63bd3759bb4c0f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c73c2220e8114c98ae1b83a8f1e8341f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c95caa41775840558a3ed58365a8091a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ca12bd31c03a4b78b3b09a971a2c13f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d2703eb420184eb2877c478e44977d16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_99d87c48b21e4480890ac29b6eccb8de",
       "max": 647021,
       "style": "IPY_MODEL_85b4d6b5e5d44c958905cc1ec15ebfe4",
       "value": 647021
      }
     },
     "d29f3bc3867049f58b9f0958a8e6fbdf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d51a86d2cbc84d01b7168de769d025ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d57050b6250f4f5289b8f612e881bbae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d633472eb37b4d1db38c55815645d22e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e1d379c88d054d1692b0b709230bb455",
       "style": "IPY_MODEL_ac22c3e385844e4b98f9696f85cbc6df",
       "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: "
      }
     },
     "db6d8ac062b54db0aefbd49a76448767": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c95caa41775840558a3ed58365a8091a",
       "style": "IPY_MODEL_2fee4e3469c5487ca5989d9d7294926d",
       "value": " 191k/? [00:00&lt;00:00, 5.81MB/s]"
      }
     },
     "de12b9d4bf8444d0a4635736e878546e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2207872f8666452488009189c1f75497",
       "style": "IPY_MODEL_24e351c723244a23aa43c05a125cf389",
       "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/pretrain/combined.pt: 100%"
      }
     },
     "deecd2f5a28e4cae8bbb3df30ae01965": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "def6ee3b20964d1c828ed9ec9167c024": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a080be236a584c578650d9a57780a76d",
       "max": 46185697,
       "style": "IPY_MODEL_deecd2f5a28e4cae8bbb3df30ae01965",
       "value": 46185697
      }
     },
     "dfa48035886d4c69acdb202779627141": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dfd9708e7bfc4935967e1a8d7d61b047": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_20ffbcc7bb8f4702a7c2b10d685470f9",
        "IPY_MODEL_9d3355b215664a93b583e019a62a0b1c",
        "IPY_MODEL_e76af0f5429449c9aa65ec2b96a5dacd"
       ],
       "layout": "IPY_MODEL_ae0a226d4ba74488beb03b4e68e86d02"
      }
     },
     "e1d379c88d054d1692b0b709230bb455": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e2fb3ec0fbd64986b7301641f8a9682b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f22f317fe13641d68a29b8a58ef9b015",
       "max": 113282980,
       "style": "IPY_MODEL_16fc7f150dd94928b5cfc7fa0f53235a",
       "value": 113282980
      }
     },
     "e3a1961ffb0341b9a7e44bbe876f30d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_4b92f64544af4be7992654b067fda995",
       "max": 38501920,
       "style": "IPY_MODEL_dfa48035886d4c69acdb202779627141",
       "value": 38501920
      }
     },
     "e5e56a1d6d7d466e9eb20cf6185bd829": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e76af0f5429449c9aa65ec2b96a5dacd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7be3bd7d50394f52b9fc71b374c385f8",
       "style": "IPY_MODEL_e5e56a1d6d7d466e9eb20cf6185bd829",
       "value": " 80.4M/80.4M [00:09&lt;00:00, 9.27MB/s]"
      }
     },
     "e833b1fca43f4a9f8ce2e0d6ab472619": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ef4a3377b12d483e86c419692a871830": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_0f6966a118434f71a6b9a610fe5b7f64",
       "max": 22743428,
       "style": "IPY_MODEL_8d5fe74725ee4d1a93b36aebf38d4547",
       "value": 22743428
      }
     },
     "ef8bf59a3d3a498085504c020a849b15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_508fe40951dd4013ba5e247fa92f809f",
        "IPY_MODEL_e2fb3ec0fbd64986b7301641f8a9682b",
        "IPY_MODEL_377023a279ad42c39ff215395a04a936"
       ],
       "layout": "IPY_MODEL_b6ea31544baf4e588fc1d00dde1f686d"
      }
     },
     "efb00c1ad6f142f4895b3ed73c21fdc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f037844d7e9a4b069cb0d6dada731b4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0502d4031a4446328ded81e647ceec98",
       "style": "IPY_MODEL_c440f1464fa7408caafcfd2dea6b4984",
       "value": " 191k/? [00:00&lt;00:00, 7.06MB/s]"
      }
     },
     "f0b6d02d55014703a83b12b59b6eb3b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_efb00c1ad6f142f4895b3ed73c21fdc4",
       "style": "IPY_MODEL_970ae87c5c9f4e6b83d171f20be599c5",
       "value": " 46.2M/46.2M [00:05&lt;00:00, 8.65MB/s]"
      }
     },
     "f22f317fe13641d68a29b8a58ef9b015": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f5b4faa5ff20486aac8140f48bf9ca0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f5ea18930223410a875714e11252c446": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa0f1760d0ee422cbafa113b26cec9f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fb3203f0a6014eac9724d37693868fc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fcc5218ac4e144ef843e3e15a3aee961": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ff11d93057634345adc26b3dfe8f198b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
